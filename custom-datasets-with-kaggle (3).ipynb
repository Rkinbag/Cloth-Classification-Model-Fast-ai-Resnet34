{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nfrom fastai.vision.all import *\npip \n\nset_seed(42)\n\npath_ori = Path('/kaggle/input/clothing-dataset-full/images_original')\npath_comp = Path('/kaggle/input/extracting-attributes-from-fashion-images-2/train')\n","metadata":{"execution":{"iopub.status.busy":"2023-06-06T07:10:51.572894Z","iopub.execute_input":"2023-06-06T07:10:51.575127Z","iopub.status.idle":"2023-06-06T07:10:53.518682Z","shell.execute_reply.started":"2023-06-06T07:10:51.574990Z","shell.execute_reply":"2023-06-06T07:10:53.517319Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2023-06-06T07:10:53.520894Z","iopub.execute_input":"2023-06-06T07:10:53.521947Z","iopub.status.idle":"2023-06-06T07:10:53.528433Z","shell.execute_reply.started":"2023-06-06T07:10:53.521901Z","shell.execute_reply":"2023-06-06T07:10:53.527192Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"img_csv = pd.read_csv('/kaggle/input/extracting-attributes-from-fashion-images-2/train.csv')","metadata":{"execution":{"iopub.status.busy":"2023-06-06T07:10:53.530787Z","iopub.execute_input":"2023-06-06T07:10:53.532159Z","iopub.status.idle":"2023-06-06T07:10:53.572139Z","shell.execute_reply.started":"2023-06-06T07:10:53.532105Z","shell.execute_reply":"2023-06-06T07:10:53.570968Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_path = '/kaggle/input/extracting-attributes-from-fashion-images-2/train'\ntrain_files = get_image_files(train_path)\n\ntest_path = '/kaggle/input/extracting-attributes-from-fashion-images-2/test'\ntest_files = get_image_files(test_path).sorted()\n\n\ntrain_df = pd.read_csv('/kaggle/input/extracting-attributes-from-fashion-images-2/train.csv')\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-06T07:10:53.579255Z","iopub.execute_input":"2023-06-06T07:10:53.582065Z","iopub.status.idle":"2023-06-06T07:10:58.267895Z","shell.execute_reply.started":"2023-06-06T07:10:53.582021Z","shell.execute_reply":"2023-06-06T07:10:58.266849Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"               file_name  label\n0  Image_train_00001.jpg      0\n1  Image_train_00002.jpg      1\n2  Image_train_00003.jpg      0\n3  Image_train_00004.jpg      0\n4  Image_train_00005.jpg      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_name</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Image_train_00001.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Image_train_00002.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Image_train_00003.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Image_train_00004.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Image_train_00005.jpg</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_df.dtypes","metadata":{"execution":{"iopub.status.busy":"2023-06-06T07:10:58.272904Z","iopub.execute_input":"2023-06-06T07:10:58.275533Z","iopub.status.idle":"2023-06-06T07:10:58.291060Z","shell.execute_reply.started":"2023-06-06T07:10:58.275491Z","shell.execute_reply":"2023-06-06T07:10:58.289956Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"file_name    object\nlabel         int64\ndtype: object"},"metadata":{}}]},{"cell_type":"code","source":"blocks = (ImageBlock, CategoryBlock)\nblocks","metadata":{"execution":{"iopub.status.busy":"2023-06-06T07:10:58.296217Z","iopub.execute_input":"2023-06-06T07:10:58.299028Z","iopub.status.idle":"2023-06-06T07:10:58.311521Z","shell.execute_reply.started":"2023-06-06T07:10:58.298983Z","shell.execute_reply":"2023-06-06T07:10:58.309736Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(<function fastai.vision.data.ImageBlock(cls: 'PILBase' = <class 'fastai.vision.core.PILImage'>)>,\n <function fastai.data.block.CategoryBlock(vocab: 'list | pd.Series' = None, sort: 'bool' = True, add_na: 'bool' = False)>)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_x = ColReader(\"file_name\", pref=(path_comp))\nget_y = ColReader(\"label\")\nget_x\nget_y","metadata":{"execution":{"iopub.status.busy":"2023-06-06T07:10:58.315257Z","iopub.execute_input":"2023-06-06T07:10:58.320604Z","iopub.status.idle":"2023-06-06T07:10:58.330606Z","shell.execute_reply.started":"2023-06-06T07:10:58.320560Z","shell.execute_reply":"2023-06-06T07:10:58.329224Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"ColReader -- {'cols': 'label', 'pref': '', 'suff': '', 'label_delim': None}:\nencodes: decodes: "},"metadata":{}}]},{"cell_type":"code","source":"from PIL import Image\nimage = Image.open('/kaggle/input/extracting-attributes-from-fashion-images-2/train/Image_train_00003.jpg')\nwidth, height = image.size\nwidth","metadata":{"execution":{"iopub.status.busy":"2023-06-06T07:10:58.333731Z","iopub.execute_input":"2023-06-06T07:10:58.336367Z","iopub.status.idle":"2023-06-06T07:10:58.362267Z","shell.execute_reply.started":"2023-06-06T07:10:58.336323Z","shell.execute_reply":"2023-06-06T07:10:58.361139Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"400"},"metadata":{}}]},{"cell_type":"code","source":"height","metadata":{"execution":{"iopub.status.busy":"2023-06-06T07:10:58.366098Z","iopub.execute_input":"2023-06-06T07:10:58.369572Z","iopub.status.idle":"2023-06-06T07:10:58.378501Z","shell.execute_reply.started":"2023-06-06T07:10:58.369531Z","shell.execute_reply":"2023-06-06T07:10:58.377100Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"533"},"metadata":{}}]},{"cell_type":"code","source":"from PIL import Image\nimage = Image.open('/kaggle/input/extracting-attributes-from-fashion-images-2/test/Image_test_00003.jpg')\nwidth, height = image.size\nwidth","metadata":{"execution":{"iopub.status.busy":"2023-06-06T07:10:58.382400Z","iopub.execute_input":"2023-06-06T07:10:58.389336Z","iopub.status.idle":"2023-06-06T07:10:58.399732Z","shell.execute_reply.started":"2023-06-06T07:10:58.389291Z","shell.execute_reply":"2023-06-06T07:10:58.398321Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"400"},"metadata":{}}]},{"cell_type":"code","source":"height","metadata":{"execution":{"iopub.status.busy":"2023-06-06T07:10:58.401565Z","iopub.execute_input":"2023-06-06T07:10:58.402339Z","iopub.status.idle":"2023-06-06T07:10:58.416536Z","shell.execute_reply.started":"2023-06-06T07:10:58.402296Z","shell.execute_reply":"2023-06-06T07:10:58.415134Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"533"},"metadata":{}}]},{"cell_type":"code","source":"tfms = aug_transforms(do_flip=True, flip_vert=True, max_rotate=0.10, max_zoom=1.3, max_warp=0.0)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-06T07:24:31.299336Z","iopub.execute_input":"2023-06-06T07:24:31.299877Z","iopub.status.idle":"2023-06-06T07:24:31.310138Z","shell.execute_reply.started":"2023-06-06T07:24:31.299831Z","shell.execute_reply":"2023-06-06T07:24:31.308836Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"dblock = DataBlock(blocks=blocks, \n                    get_x=get_x,\n                    get_y=get_y,\n                   item_tfms=Resize(480,method='squish'),\n                   batch_tfms=tfms,splitter=RandomSplitter(valid_pct=0.2, seed=42))\ndblock\n","metadata":{"execution":{"iopub.status.busy":"2023-06-06T07:30:29.508982Z","iopub.execute_input":"2023-06-06T07:30:29.509504Z","iopub.status.idle":"2023-06-06T07:30:29.531728Z","shell.execute_reply.started":"2023-06-06T07:30:29.509460Z","shell.execute_reply":"2023-06-06T07:30:29.530648Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"<fastai.data.block.DataBlock at 0x7852eb745350>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aug_transforms?","metadata":{"execution":{"iopub.status.busy":"2023-06-06T07:11:01.394841Z","iopub.execute_input":"2023-06-06T07:11:01.397346Z","iopub.status.idle":"2023-06-06T07:11:01.507589Z","shell.execute_reply.started":"2023-06-06T07:11:01.397302Z","shell.execute_reply":"2023-06-06T07:11:01.506471Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[0;31mSignature:\u001b[0m\n\u001b[0maug_transforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mmult\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'float'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mdo_flip\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mflip_vert\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mmax_rotate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'float'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mmin_zoom\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'float'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mmax_zoom\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'float'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mmax_lighting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'float'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mmax_warp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'float'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mp_affine\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'float'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mp_lighting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'float'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mxtra_tfms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'list'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int | tuple'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'bilinear'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mpad_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'reflection'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0malign_corners\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mmin_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;31mDocstring:\u001b[0m Utility func to easily create a list of flip, rotate, zoom, warp, lighting transforms.\n\u001b[0;31mFile:\u001b[0m      /opt/conda/lib/python3.7/site-packages/fastai/vision/augment.py\n\u001b[0;31mType:\u001b[0m      function\n"},"metadata":{}}]},{"cell_type":"code","source":"dls = dblock.dataloaders(img_csv)\ndls","metadata":{"execution":{"iopub.status.busy":"2023-06-06T07:24:36.224125Z","iopub.execute_input":"2023-06-06T07:24:36.224635Z","iopub.status.idle":"2023-06-06T07:24:41.126686Z","shell.execute_reply.started":"2023-06-06T07:24:36.224591Z","shell.execute_reply":"2023-06-06T07:24:41.125509Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"<fastai.data.core.DataLoaders at 0x78530dd9d410>"},"metadata":{}}]},{"cell_type":"code","source":"dls.show_batch()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn = vision_learner(dls, resnet34, metrics=accuracy,pool=nn.AdaptiveAvgPool2d)\n\nlearn\n","metadata":{"execution":{"iopub.status.busy":"2023-06-06T07:30:43.838633Z","iopub.execute_input":"2023-06-06T07:30:43.839226Z","iopub.status.idle":"2023-06-06T07:30:45.138388Z","shell.execute_reply.started":"2023-06-06T07:30:43.839176Z","shell.execute_reply":"2023-06-06T07:30:45.137145Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"<fastai.learner.Learner at 0x7852eb745e50>"},"metadata":{}}]},{"cell_type":"code","source":"lrs = learn.lr_find(suggest_funcs=(minimum, steep, valley, slide))","metadata":{"execution":{"iopub.status.busy":"2023-06-06T07:30:45.144671Z","iopub.execute_input":"2023-06-06T07:30:45.147856Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      0.00% [0/1 00:00&lt;?]\n    </div>\n    \n\n\n    <div>\n      <progress value='12' class='' max='229' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      5.24% [12/229 00:22&lt;06:42 3.0465]\n    </div>\n    "},"metadata":{}}]},{"cell_type":"code","source":"learn.fit_one_cycle(3,lrs.valley)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn.unfreeze()\nlrs = learn.lr_find(suggest_funcs=(minimum, steep, valley, slide))","metadata":{"execution":{"iopub.status.busy":"2023-06-06T07:29:14.871668Z","iopub.status.idle":"2023-06-06T07:29:14.872609Z","shell.execute_reply.started":"2023-06-06T07:29:14.872315Z","shell.execute_reply":"2023-06-06T07:29:14.872343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn.fit_one_cycle(12,slice(lrs.minimum,lrs.slide))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn.fine_tune(10,0.001737800776027143)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"probs, target = learn.get_preds(dl=dls.valid)\nerror_rate(probs, target)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"probs, target = learn.tta(dl=dls.valid)\nerror_rate(probs, target)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"probs, _ = learn.tta(dl=dls.test_dl(test_files))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = probs.argmax(dim=1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dls.vocab[preds]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission=pd.read_csv('/kaggle/input/extracting-attributes-from-fashion-images-2/sample_submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.label = dls.vocab[preds]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.to_csv('112121.csv',index=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FileLink(\"111.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}